#Conexión con el Google Cloud
from google.Conjuntosdedatos import Google Cloud
.Conjuntosdedatos.mount('/content/.Conjuntosdedatos') 


#importamos librerias
import numpy as np
import pandas as pd
import os
from sklearn.datasets import load_files
import torch
import torch.nn as nn
import torchvision.models as models

class ResNet152(nn.Module):
    def _init_(self, num_classes):
        super(ResNet152, self)._init_()
        self.resnet152 = models.resnet152(pretrained=True)
        in_features = self.resnet152.fc.in_features
        self.resnet152.fc = nn.Linear(in_features, num_classes)

    
        in_features = self.resnet152.fc.in_features
        self.resnet152.fc = nn.Linear(in_features,

        in_features = self.resnet152.fc.in_features
        self.resnet
def forward(self, x):
        return self.resnet152(x)

# Crea una instancia de ResNet152
num_classes = 
num_classes = 
20000  # Número de clases en el conjunto de datos
model = ResNet152(num_classes)

from tqdm import tqdm
from PIL import ImageFile



# Cargar las imágenes con sus categorías respectivas
path = "/content/.Conjuntosdedatos/melanomas/Data1/"
data = load_files(path)


#imprimimos file names y targets
print("Filename: \n", data['filenames'][:10])
print("Targets: \n", data['target'][:10])
Filename: 
 ['/content/.Conjuntosdedatos/melanomas/Data1/melanoma/melanomas (4000).png'
 '/content/.Conjuntosdedatos/melanomas/Data1/melanoma/lunares (4000).png'
 '/content/.Conjuntosdedatos/melanomas/Data1/melanomas/etapa1 (3000).png'
 '/content/.Conjuntosdedatos/melanomas/Data1/melanomas/etapa2 (3000).png'
 ''/content/.Conjuntosdedatos/melanomas/Data1/melanomas/etapa3 (3000).png''
 ''/content/.Conjuntosdedatos/melanomas/Data1/melanomas/etapa4(3000).png''
Targets: 
 [2 2 7 8 5 5 1 9 0 3]
[ ]
# Poniendo las etiquetas a la data
target = np_utils.to_categorical(np.array(data['target']), 10)
target
test_targets=data['target']
#********************************
[ ]
print (len(data['filenames']))
3836
[ ]
# Dividiendo la data entre un set de validación y un set de entrenamiento
train_files, train_targets = data['filenames'][:1918], target[:1918]
valid_files, valid_targets = data['filenames'][1919:2685], target[1919:2685]
#test_files = data['filenames'][2686:]
#test_targets = test_targets[2686:] #*****************************************************
test_files,test_targets= data['filenames'][2686:],target[2686:]
Haz doble clic (o ingresa) para editar

[ ]
# Asegurando un tensor dado un url.
def path_to_tensor(img_path):
# Cargando la imagen
  img = image.load_img(img_path, target_size=(150, 150))
# Convirtiendo la imagen en un array
  x = image.img_to_array(img)
  return np.expand_dims(x, axis=0)
  
def paths_to_tensor(img_paths):
# Asegurando una lista de tensor dado un url
  list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]
  return np.vstack(list_of_tensors)
[ ]
# Pre-procesando la data para  resnet152
datagen = ImageDataGenerator(
    rescale=1.0/255,           # Normalización
    rotation_range=20,         # Rotación aleatoria
    width_shift_range=0.2,     # Desplazamiento horizontal aleatorio
    height_shift_range=0.2,    # Desplazamiento vertical aleatorio
    horizontal_flip=True       # Volteo horizontal aleatorio
)

# Directorio que contiene las imágenes
image_dir = "/content/.Conjuntosdedatos"
batch_size = 32

# Cargar imágenes y aplicar aumentos de datos
data_generator = datagen.flow_from_directory(
    image_dir,
    target_size=(224, 224),   # Tamaño deseado
    batch_size=batch_size,
    class_mode='categorical'  # Otra opción: 'binary' si es una tarea de clasificación binaria
)
# Guardando la data pre-procesada en un archivo .npy
np.save("/content/drive/MyDrive/proces/augmented_training_tensors.npy", train_tensors)
np.save("/content/drive/MyDrive/proces/augmented_validation_tensors.npy",valid_tensors)
#/**************************************
np.save("/content/drive/MyDrive/proces/augmented_test_tensors.npy",test_tensors)
[ ]
# Cargando la data
train_tensors = np.load("/content/drive/MyDrive/proces/augmented_training_tensors.npy")
valid_tensors = np.load("/content/drive/MyDrive/proces/augmented_validation_tensors.npy")
#/**************************************
test_tensors = np.load("/content/drive/MyDrive/proces/augmented_test_tensors.npy")
[ ]
#Establecemos parametros para entrenamiento

epocas=100
longitud, altura = 224, 224
batch_size = 32
#***********************************
pasos = 100
validation_steps = 300
tamano_filtro1 = (3, 3)
tamano_filtro2 = (2, 2)
tamano_pool = (2, 2)
clases = 10
lr = 0.0001
[ ]

cnn = Sequential()
cnn.add(Convolution2D(16, tamano_filtro1, padding ="same", input_shape=(longitud, altura, 3), activation='relu'))
cnn.add(MaxPooling2D(pool_size=tamano_pool))

cnn.add(Convolution2D(32, tamano_filtro2, padding ="same"))
cnn.add(MaxPooling2D(pool_size=tamano_pool))

cnn.add(Convolution2D(64, tamano_filtro2, padding ="same"))
cnn.add(MaxPooling2D(pool_size=tamano_pool))

cnn.add(Convolution2D(128, tamano_filtro2, padding ="same"))
cnn.add(MaxPooling2D(pool_size=tamano_pool))

cnn.add(Flatten())
cnn.add(Dense(256, activation='relu'))
cnn.add(Dropout(0.5))
cnn.add(Dense(clases, activation='softmax'))

cnn.compile(loss='categorical_crossentropy',
            optimizer='adam',
            metrics=['accuracy'])
[ ]
cnn.summary()
[ ]
#Ponemos el modelo a entrenar

tensorboardDenso = TensorBoard(log_dir='/content/logs/uno')

cnn.fit(
    train_tensors,
    train_targets,
    steps_per_epoch=pasos,
    epochs=epocas,
    validation_data=(valid_tensors,valid_targets),
    validation_steps=validation_steps,
    callbacks=[tensorboardDenso]
    )
Epoch 1/100
 96/100 [===========================>..] - ETA: 0s - loss: 2.0665 - accuracy: 0.2763WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 300 batches). You may need to use the repeat() function when building your dataset.
100/100 [==============================] - 12s 28ms/step - loss: 2.0472 - accuracy: 0.2833 - val_loss: 1.7814 - val_accuracy: 0.3760
Epoch 2/100
100/100 [==============================] - 1s 10ms/step - loss: 1.5439 - accuracy: 0.4960
Epoch 3/100
100/100 [==============================] - 1s 10ms/step - loss: 1.2403 - accuracy: 0.5851
Epoch 4/100
100/100 [==============================] - 1s 10ms/step - loss: 0.9060 - accuracy: 0.6962
Epoch 5/100
100/100 [==============================] - 1s 10ms/step - loss: 0.6678 - accuracy: 0.7808
Epoch 6/100
100/100 [==============================] - 1s 10ms/step - loss: 0.5087 - accuracy: 0.8248
Epoch 7/100
100/100 [==============================] - 1s 12ms/step - loss: 0.3349 - accuracy: 0.8879
Epoch 8/100
100/100 [==============================] - 1s 12ms/step - loss: 0.2583 - accuracy: 0.9169
Epoch 9/100
100/100 [==============================] - 1s 11ms/step - loss: 0.1806 - accuracy: 0.9409
Epoch 10/100
100/100 [==============================] - 1s 11ms/step - loss: 0.1768 - accuracy: 0.9424
Epoch 11/100
100/100 [==============================] - 1s 10ms/step - loss: 0.1362 - accuracy: 0.9590
Epoch 12/100
100/100 [==============================] - 1s 10ms/step - loss: 0.1304 - accuracy: 0.9560
Epoch 13/100
100/100 [==============================] - 1s 10ms/step - loss: 0.1655 - accuracy: 0.9565
Epoch 14/100
100/100 [==============================] - 1s 10ms/step - loss: 0.1159 - accuracy: 0.9650
Epoch 15/100
100/100 [==============================] - 1s 10ms/step - loss: 0.1269 - accuracy: 0.9580
Epoch 16/100
100/100 [==============================] - 1s 10ms/step - loss: 0.1218 - accuracy: 0.9595
Epoch 17/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0873 - accuracy: 0.9710
Epoch 18/100
100/100 [==============================] - 1s 10ms/step - loss: 0.1090 - accuracy: 0.9690
Epoch 19/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0643 - accuracy: 0.9800
Epoch 20/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0568 - accuracy: 0.9840
Epoch 21/100
100/100 [==============================] - 2s 15ms/step - loss: 0.0666 - accuracy: 0.9830
Epoch 22/100
100/100 [==============================] - 1s 15ms/step - loss: 0.0507 - accuracy: 0.9825
Epoch 23/100
100/100 [==============================] - 1s 14ms/step - loss: 0.0401 - accuracy: 0.9845
Epoch 24/100
100/100 [==============================] - 1s 13ms/step - loss: 0.1312 - accuracy: 0.9589
Epoch 25/100
100/100 [==============================] - 1s 11ms/step - loss: 0.0966 - accuracy: 0.9700
Epoch 26/100
100/100 [==============================] - 1s 10ms/step - loss: 0.1019 - accuracy: 0.9690
Epoch 27/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0914 - accuracy: 0.9725
Epoch 28/100
100/100 [==============================] - 1s 10ms/step - loss: 0.1188 - accuracy: 0.9635
Epoch 29/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0857 - accuracy: 0.9700
Epoch 30/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0475 - accuracy: 0.9860
Epoch 31/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0421 - accuracy: 0.9850
Epoch 32/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0446 - accuracy: 0.9855
Epoch 33/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0389 - accuracy: 0.9870
Epoch 34/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0797 - accuracy: 0.9745
Epoch 35/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0607 - accuracy: 0.9815
Epoch 36/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0918 - accuracy: 0.9695
Epoch 37/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0593 - accuracy: 0.9800
Epoch 38/100
100/100 [==============================] - 1s 11ms/step - loss: 0.0529 - accuracy: 0.9825
Epoch 39/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0662 - accuracy: 0.9805
Epoch 40/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0609 - accuracy: 0.9830
Epoch 41/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0456 - accuracy: 0.9885
Epoch 42/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0550 - accuracy: 0.9850
Epoch 43/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0492 - accuracy: 0.9830
Epoch 44/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0455 - accuracy: 0.9885
Epoch 45/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0506 - accuracy: 0.9860
Epoch 46/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0487 - accuracy: 0.9845
Epoch 47/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0574 - accuracy: 0.9855
Epoch 48/100
100/100 [==============================] - 1s 11ms/step - loss: 0.0515 - accuracy: 0.9835
Epoch 49/100
100/100 [==============================] - 1s 11ms/step - loss: 0.0380 - accuracy: 0.9880
Epoch 50/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0424 - accuracy: 0.9880
Epoch 51/100
100/100 [==============================] - 1s 11ms/step - loss: 0.0319 - accuracy: 0.9905
Epoch 52/100
100/100 [==============================] - 1s 10ms/step - loss: 0.1235 - accuracy: 0.9645
Epoch 53/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0782 - accuracy: 0.9765
Epoch 54/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0735 - accuracy: 0.9775
Epoch 55/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0441 - accuracy: 0.9895
Epoch 56/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0293 - accuracy: 0.9905
Epoch 57/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0499 - accuracy: 0.9845
Epoch 58/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0374 - accuracy: 0.9875
Epoch 59/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0329 - accuracy: 0.9900
Epoch 60/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0665 - accuracy: 0.9835
Epoch 61/100
100/100 [==============================] - 1s 11ms/step - loss: 0.0392 - accuracy: 0.9895
Epoch 62/100
100/100 [==============================] - 1s 11ms/step - loss: 0.0714 - accuracy: 0.9815
Epoch 63/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0553 - accuracy: 0.9860
Epoch 64/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0249 - accuracy: 0.9925
Epoch 65/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0600 - accuracy: 0.9880
Epoch 66/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0505 - accuracy: 0.9855
Epoch 67/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0395 - accuracy: 0.9855
Epoch 68/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0554 - accuracy: 0.9825
Epoch 69/100
100/100 [==============================] - 1s 11ms/step - loss: 0.0761 - accuracy: 0.9820
Epoch 70/100
100/100 [==============================] - 1s 12ms/step - loss: 0.1067 - accuracy: 0.9735
Epoch 71/100
100/100 [==============================] - 2s 16ms/step - loss: 0.1053 - accuracy: 0.9690
Epoch 72/100
100/100 [==============================] - 2s 16ms/step - loss: 0.0581 - accuracy: 0.9855
Epoch 73/100
100/100 [==============================] - 1s 13ms/step - loss: 0.0399 - accuracy: 0.9880
Epoch 74/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0217 - accuracy: 0.9935
Epoch 75/100
100/100 [==============================] - 1s 11ms/step - loss: 0.0285 - accuracy: 0.9910
Epoch 76/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0617 - accuracy: 0.9820
Epoch 77/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0444 - accuracy: 0.9850
Epoch 78/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0352 - accuracy: 0.9890
Epoch 79/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0186 - accuracy: 0.9935
Epoch 80/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0223 - accuracy: 0.9940
Epoch 81/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0196 - accuracy: 0.9970
Epoch 82/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0256 - accuracy: 0.9920
Epoch 83/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0186 - accuracy: 0.9940
Epoch 84/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0668 - accuracy: 0.9820
Epoch 85/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0651 - accuracy: 0.9830
Epoch 86/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0739 - accuracy: 0.9780
Epoch 87/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0503 - accuracy: 0.9860
Epoch 88/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0753 - accuracy: 0.9830
Epoch 89/100
100/100 [==============================] - 1s 11ms/step - loss: 0.0483 - accuracy: 0.9840
Epoch 90/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0593 - accuracy: 0.9845
Epoch 91/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0461 - accuracy: 0.9865
Epoch 92/100
100/100 [==============================] - 1s 10ms/step - loss: 0.0758 - accuracy: 0.9795
Epoch 93/100
100/100 [==============================] - 1s 11ms/step - loss: 0.0752 - accuracy: 0.9845
Epoch 94/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0354 - accuracy: 0.9895
Epoch 95/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0389 - accuracy: 0.9860
Epoch 96/100
100/100 [==============================] - 1s 12ms/step - loss: 0.0552 - accuracy: 0.9845
WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.
Epoch 97/100
100/100 [==============================] - 0s 555us/step - loss: 0.0552 - accuracy: 0.9845
<tensorflow.python.keras.callbacks.History at 0x7f87bc04fb80>
[ ]
# Vista de tensorboard para los graficos del entrenamiento 
# Start tensorboard

%load_ext tensorboard
%tensorboard --logdir logs


[ ]
#************************************************************
#Categorizar una imagen del archivo
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_curve
#from sklearn.metrics import score
from sklearn.metrics import confusion_matrix
#modelo = '/content/drive/MyDrive/modelo5/modelo.h5'
#pesos_modelo = '/content/drive/MyDrive/modelo5/pesos.h5'
#cnn = load_model(modelo)
#cnn.load_weights(pesos_modelo)
y_pred=cnn.predict(test_tensors)
#accuracy_score(y_pred, test_targets)
#confusion_matrix(y_pred, test_targets)
test_targets.shape
(1150, 10)
[ ]
#Guardamos el modelo para su descarga y su posterior uso 
target_dir = '/content/'
if not os.path.exists(target_dir):
  os.mkdir(target_dir)
cnn.save('/content/drive/MyDrive/modelo4/modelo.h5')
cnn.save_weights('./drive/MyDrive/modelo4/pesos.h5')
[ ]
#El equipo es Linux. Listemos el contenido de la carpeta actual para ver que se exporto el modelo
!ls
[ ]
#Para convertirlo a tensorflow.js, primero debemos instalar la libreria
!pip install tensorflowjs
Haz doble clic (o ingresa) para editar

[ ]
#Crear carpeta donde se colocaran los archivos resultantes
!mkdir carpeta_salida
[ ]
#Realizar la exportacion a la carpeta de salida
!tensorflowjs_converter --input_format keras modelo.h5 carpeta_salida
[ ]
#Confirmar que en la carpeta de salida se hayan generado los archivos. Deben aparecer archivos "bin" y "json"
!ls carpeta_salida
[ ]
#Categorizar una imagen del archivo
longitud, altura = 150, 150
modelo = '/content/drive/MyDrive/modelo4/modelo.h5'
pesos_modelo = '/content/drive/MyDrive/modelo4/pesos.h5'

cnn = load_model(modelo)
cnn.load_weights(pesos_modelo)

def predict(file):
  x = load_img(file, target_size=(longitud, altura))

[ ]
test_files
array(['/content/.Conjuntosdedatos/melanomas/Data1/melanoma/melanomas (1000).png',
       '/content/.Conjuntosdedatos/melanomas/Data1/melanoma/lunares (800).png',
       '/content/.Conjuntosdedatos/melanomas/Data1/melanoma/etapa1 (2000).png', ...,
       '/content/.Conjuntosdedatos/melanomas/Data1/melanoma/etapa2(3000).png,
       '/content/.Conjuntosdedatos/melanomas/Data1/melanoma/etapa3 (870).png',
       '/content/.Conjuntosdedatos/melanomas/Data1/melanoma/etapa4 (1000).png'],
      dtype='<U3000')
[ ]
np.shape(test_targets)
(2685, 10)
